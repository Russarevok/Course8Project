---
title: "Practical Machine Learning Project"
author: "Russell Scherer"
date: "2023-12-29"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Load, clean, prepare and explore the data

```{r load and clean the data}
library(dplyr)
library(caret)
###library(rpart)

###
### Load in test and training data.
###
training_df = read.csv("./Data/pml-training.csv")
testing_df = read.csv("./Data/pml-testing.csv")

### Look at data
str(training_df)
names(training_df)

### Look at counts for each classe (target variable) to see if there is any imbalanced (underrepresented) outcome values.
g <- group_by(training_df, training_df$classe)
summarise(g,count = n())


### Look at data - but it's has too many columns to view this way:
#View(training_df)
#View(testing_df)

# Remove all rows from training dataset where new_window == yes as they are not in the testing data
training_df_1 <- filter(training_df, new_window=='no') 

# Look at columns that should not be features based on the problem we are trying to solve
#View(training_df_1)

#install.packages("tidyverse")
library(tidyverse)

# get rid of all columns that are empty
training_df_2 <- discard(training_df_1,~all(is.na(.) | . == ""))
#View(training_df_2)

# remove all columns that will are not features or the outcome variable
# X, user_name, raw_timestamp_part_1, raw_timestamp_part_2, new_window, num_window
colsToRemove <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "new_window", "num_window", "cvtd_timestamp")
training_df_final <- select(training_df_2,-c(colsToRemove))
#View(training_df_final)

# set seed to ensure that the results can be reproduced by others
set.seed(21)

### Split the training data set into a training and validation set for out of sample error testing.
inTrain <- createDataPartition(y=training_df_final$classe, p=0.7, list=FALSE)
training <- training_df_final[inTrain,]
validation <- training_df_final[-inTrain,]

# clean up test data as well
testing_df_2 <- discard(testing_df,~all(is.na(.) | . == ""))
#View(testing_df_2)

testing_df_final <- select(testing_df_2,-c(colsToRemove))
#View(testing_df_final)

```

## How I built my model and used cross validation  

### Model  
Use random forest because we are most concerned about accuracy and less concerned about interpretability and performance.  
- Use parallelism because random forest is very resource intensive.  


### Cross validation  
Apply k-fold on training data set (i.e., training data within training data set (70/30) split.  We set aside 30% of training data for validation  
so that we can get out of sample error estimate.  
- We use a smaller number of folds (5) because it results in less variance  
- Our sample sizes within each fold is fairly large so we are less concerned about bias.  

```{r Cross Validation, echo=FALSE}
# Cross validation
# apply k-fold on training data set.

# Use random forest because we are most concerned about accuracy and less concerned about interpretability and performance.
# We use parallelism because random forest is very resource intensive.
# This speeds up the training considerably.
library(doParallel)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

# We use a smaller number because it results in less variance
# and our sample size are fairly large so we are less concerned about bias.
train_control<- trainControl(method="cv", number=5)

rf_model <- train(classe~.,data=training, method="rf", trControl=train_control)
# look at the model results
rf_model$finalModel

## Stop the cluster:
stopCluster(cl)
```


### Get out of sample error - used to estimate errors on independent data.

Expected out of sample error is.  

``` {r Get expected out of sample error}
rf_model_pred <- predict(rf_model,validation)
validation$predRight <- rf_model_pred == validation$classe
table(rf_model_pred,validation$classe)
```

### Therefore, the expected error rate for out of sample is about:  
( 10 + 8 + 30 + 3 + 2 ) / (1641 + 1103 + 997 + 914 + 1055) = ( 53 / 5710 ) * 100 = 0.93%  

It is higher than in sample error rate of 0.73%